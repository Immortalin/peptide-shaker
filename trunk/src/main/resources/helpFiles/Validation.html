<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<HTML>
    <HEAD>
        <TITLE></TITLE>
    </HEAD>
    <BODY>
        <a name="#top"/>
        <H2>Validation</H2>

        <h3>General</h3>
        For every Group you can:
        <ul>
            <li>Optimize the estimator's accuracy</li>
            <li>Set the threshold for the identifications</li>
        </ul>
        <br>

        <a name="Group_Selection"></a>
        <h3>Group selection</h3>
        <p align="justify">
            The standard populations inspected by <b>PeptideShaker</b> are PSMs, peptides and proteins. However, if statistical significance is ensured PSMs will be separated according to their charge. 
            Similarly, peptides can be separated based on their modification status.
            <br><br>
            This grouping strategy will allow you to increase the sensitivity of the processing without compromising robustness. Note however that changes at the PSM level will affect results at the Peptide and Protein levels. Similarly changes at the Peptide level will affect the Protein level. It is thus important to apply the changes upstream first!
            <br><br>
            For more information about the interests of protein grouping see http://www.ncbi.nlm.nih.gov/pubmed/21500347.
        </p>
        <br><br><br>

        <a name="Optimize_Estimator_Accuracy"></a>
        <h3>Optimize Confidence Estimator Accuracy</h3>
        <p align="justify">
            The estimators plot will help you to improve the accuracy of confidence estimation. 
            By default, the PEP window is set to a minimal value Nmax: the maximum amount of target hits comprised between two 
            subsequent decoy hits.
            <br><br>
            When the PEP is confidently estimated, probabilistic estimators can be used. Sometimes however, the PEP cannot be accurately estimated, for small populations for instance. The confidence and probabilistic estimators will then not be reliable anymore. It is advised to trust only 
            score and classical FDR. By default, classical estimation is selected.
        </p>
        <br><br><br>

        <a name="Setting_the_Threshold"></a>
        <h3>Setting the Threshold</h3>
        <p align="justify">
            The score threshold used, illustrated in red in the confidence plot, can be changed to meet three kind of requirements:
            <ul>
            <li>Confidence: all hits presenting a better confidence than the threshold will be validated.</li>
            <li>False Discovery Rate (FDR): <b>PeptideShaker</b> will validate the largest set of identifications with an FDR lower than the threshold. At 1% FDR, a maximum of 1% of the validated identifications will be false positives. The FDR can be estimated classically or probabilistically. When the confidence estimation is not accurate the probabilistic estimator should not be used! When Nmax or the number of validated hits are small (typically less than 100) low FDR threshold (typically 1%) should not be applied! See http://www.ncbi.nlm.nih.gov/pubmed/21500347 for more information about the minimal acceptable FDR.</li>
            <li>False Negative Rate (FNR): <b>PeptideShaker</b> will validate the smallest set of identifications with an FNR higher than the threshold. At 1% FNR, 99% of the potential true positives will be validated. This threshold should not be used when the confidence is not accurately estimated!</li>
            </ul>
        <br><br>
        By default the threshold is set to 1% FDR.
        </p>
        <br><br><br>

        <a name="Identification_summary"></a>
        <h3>Identification summary</h3>
        <p align="justify">
            The identification summary provides essential metrics of the selected group.
            <ul>
            <li>Total TP: the estimated total amount of the true positives which can be found in this dataset without any threshold.</li>
            <li>Nmax: the maximal amount of target hits comprised between two subsequent decoy hits. If this value is lower than 100 the accuracy of the confidence estimation should be verified! For more information about Nmax, please see http://www.ncbi.nlm.nih.gov/pubmed/21500347.</li>
            <li># Validated Hits: the number of identification retained with the selected threshold.</li>
            <li># TP: the estimated amount of true positives identifications contained in the validated identifications.</li>
            <li># FP: the estimated amount of false positives identifications contained in the validated identifications.</li>
            <li># Confidence: the lowest confidence found in the validated identifications.</li>
            <li># FDR: the proportion of false positives in the validated hits. At 1% FDR, 100 validated identifications contain one false positive.</li>
            <li># FNR: the proportion of non validated true positives. At 1% FNR, 99% of the estimated total amount of the true positives will be validated. </li>
            </ul>
        </p>
        <br><br><br>

        <a name="Confidence_plot"></a>
        <h3>Confidence plot</h3>
        <p align="justify">
            This plot displays the confidence plotted against the score of the selected group identifications. If the confidence is fluctuating, the confidence estimation might not be robust enough and should be optimized as described above.
            <br><br>
            The red vertical line indicates the chosen threshold. The red area on the left of the threshold illustrates the amount of retained true positives. The green area on the right of the threshold illustrates the amount of potential true positives not validated: the false negatives.
        </p>
        <br><br><br>

        <a name="FDR_FNR_plot"></a>
        <h3>FDR/FNR plot</h3>
        <p align="justify">
            This plot displays the two FDR estimators and the FNR estimator plotted against the score of the selected group identifications. If the two FDR estimators do not agree, the confidence estimation might not be robust enough and should be optimized as described above.
            <br><br>
            Three points indicate the FDR and FNR of the validated identifications.
        </p>
        <br><br><br>

        <a name="ROC_plot"></a>
        <h3>Benefit/Cost plot</h3>
        <p align="justify">
            This plot displays the benefit which can be expected, the proportion of retained true positives (1-FNR), plotted against the cost of the selected benefit, the proportion of false positive identifications (FDR). In other words it is a ROC curve of for the selected group.
            <br><br>
            A point indicate the performance at the selected threshold. It is possible to move this point along the curve in order to optimize the threshold balancing between quality and quantity. If the point diverges away from the curve the confidence estimation should be optimized as described above.
        </p>
        <br><br><br>

        <a name="PEP_plot"></a>
        <h3>PEP plot</h3>
        <p align="justify">
            This plot displays the Posterior Error Probability (PEP) plotted against the score of the selected group. If the PEP is fluctuating the confidence estimation is not robust enough and should be optimized as described above.
        </p>
        <br><br><br>

        <a name="FDR_plot"></a>
        <h3>FDR plot</h3>
        <p align="justify">
            This plot displays the the probabilistic FDR plotted against the classical FDR for identifications with a confidence >0. The curve should closely follow the black diagonal. If this is not the case the confidence estimation should be optimized as described above.
        </p>
        
        <br><br><br><br>
        <a href="#top">Go to top of page</a><br><br>

    </BODY>
</HTML>